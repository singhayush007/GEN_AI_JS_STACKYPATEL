# Generative AI with Node.js, LangChain, TypeScript & Open AI & Google Gemini

This repository contains my learning and practice code while studying **Generative AI with Node.js and TypeScript**.
The implementation uses **Google Gemini API** **OpenAI**, inspired by Stacky Patel Generative AI course.

---

## ğŸ“š Lecture 01 â€“ Introduction & Setup

### ğŸ”§ What You'll Learn in This Lecture:

âœ… How to get and use your **Google Gemini API key**  
âœ… Understanding **Google Gemini services and models**  
âœ… Setting up a **Node.js project with TypeScript**  
âœ… Installing and using the **Google Generative AI (Gemini) Node.js SDK**  
âœ… Best practices for organising a **Generative AI project**

---

## ğŸ“š Lecture 02 â€“ Gemini Chat Application (CLI Based)

### ğŸ”§ What You'll Learn in This Lecture:

âœ… Setting up **Google Gemini client** using Node.js  
âœ… Loading environment variables securely with **dotenv**  
âœ… Understanding **Gemini models** (`gemini-flash-latest`)  
âœ… Using **system instructions** to control AI behaviour  
âœ… Creating a **chat-based conversation** using Gemini  
âœ… Taking real-time user input from terminal  
âœ… Handling errors and graceful exit in a GenAI app

---

## ğŸ“š Lecture 03 â€“ Tool Calling with Gemini (Weather Fetch App)

### ğŸ”§ What You'll Learn in This Lecture:

âœ… Understanding **Tool Calling (Function Calling)** in Generative AI  
âœ… How Gemini decides **when to call a tool** vs when to respond normally  
âœ… Defining **custom tools / functions** for Gemini  
âœ… Implementing a **Weather Fetch Tool**  
âœ… Passing structured parameters (e.g. city name) from AI to function  
âœ… Executing real-world logic (API or mock data) from tool calls  
âœ… Returning tool results back to Gemini  
âœ… Complete flow: **User â†’ AI â†’ Tool â†’ AI â†’ Final Response**

### ğŸ› ï¸ What We Built:

- A CLI-based AI application where:
  - User asks questions like _"What is the weather in Delhi?"_
  - Gemini automatically triggers a **weather tool**
  - The tool fetches weather data
  - Gemini formats the data into a **human-friendly answer**

This lecture explains how **LLMs interact with external systems**, which is a **core concept for production-level GenAI apps**.

---

## ğŸ“š Lecture 04 â€“ Multimodal AI with DALLÂ·E & Whisper

### ğŸ”§ What You'll Learn in This Lecture:

âœ… Understanding **Multimodal AI** (Text, Image, Audio)  
âœ… Using **DALLÂ·E** for **Text-to-Image generation**  
âœ… Using **Whisper** for **Text-to-Speech (Voice generation)**  
âœ… Handling **binary outputs** (images & audio files) in Node.js  
âœ… Saving generated images and audio locally  
âœ… Managing TypeScript types and error handling  
âœ… Building real-world GenAI utilities using Node.js

### ğŸ› ï¸ What We Built:

#### ğŸ¨ Text to Image (DALLÂ·E)

- User provides a text prompt
- AI generates an image based on the prompt
- Image is saved locally (e.g. `.png` file)

#### ğŸ”Š Text to Voice (Whisper / TTS)

- User provides text input
- AI converts text into **natural-sounding speech**
- Audio file is generated and stored (e.g. `.mp3` / `.wav`)

This lecture demonstrates how GenAI goes **beyond chat**, enabling:

- Image generation
- Voice generation
- Creative & production-ready AI workflows

---

## ğŸ“š Lecture 05 â€“ Vector Embeddings & Similarity Search

### ğŸ”§ What You'll Learn in This Lecture:

âœ… What are **Vector Embeddings** and why they are important in GenAI  
âœ… Converting text into **numerical vector representations**  
âœ… Understanding **semantic meaning** through embeddings  
âœ… What is **Cosine Similarity** and how it works  
âœ… What is **Dot Product Similarity**  
âœ… Difference between **Cosine Similarity vs Dot Similarity**  
âœ… Measuring similarity between two pieces of text

### ğŸ§  Key Concepts Explained:

- **Vector Embeddings**

  - Text is converted into high-dimensional vectors
  - Similar meanings â†’ vectors closer to each other

- **Cosine Similarity**

  - Measures the **angle** between two vectors
  - Focuses on direction, not magnitude
  - Value ranges between `-1` and `1`
  - Commonly used in semantic search

- **Dot Product Similarity**
  - Measures similarity based on vector multiplication
  - Depends on both **direction and magnitude**
  - Faster but less normalized than cosine similarity

---

## ğŸ“š Lecture 06 â€“ Vector Databases with ChromaDB (Semantic Search)

### ğŸ”§ What You'll Learn in This Lecture:

âœ… What is a **Vector Database** and why it is needed  
âœ… How vector databases store and search embeddings  
âœ… Introduction to **ChromaDB**  
âœ… Creating and managing **collections** in ChromaDB  
âœ… Storing text data as **embeddings**  
âœ… Using metadata (role, ids) with vectors  
âœ… Performing **semantic similarity search**  
âœ… Understanding how vector DBs power **RAG systems**

### ğŸ§  Key Concepts Explained:

- **Vector Database**

  - A specialized database designed to store **vector embeddings**
  - Enables fast **similarity search** instead of exact matching
  - Used in semantic search, chat history memory, and RAG pipelines

- **ChromaDB**

  - Lightweight, open-source vector database
  - Easy to use with Node.js
  - Ideal for learning and local GenAI projects

- **Semantic Search**
  - Search is based on **meaning**, not keywords
  - User query is converted into an embedding
  - Closest vectors are returned using similarity metrics

## ğŸ“š Lecture 07 â€“ LangChain Fundamentals (Prompts, Batching & Chunking)

### ğŸ”§ What You'll Learn in This Lecture:

âœ… Introduction to **LangChain** and why it is used  
âœ… Setting up **ChatOpenAI** model with LangChain  
âœ… Using **PromptTemplate** for dynamic prompts  
âœ… Single LLM calls using LangChain  
âœ… Batch processing multiple prompts efficiently  
âœ… Handling long text using **Text Chunking**  
âœ… Understanding **RecursiveCharacterTextSplitter**  
âœ… Building structured and reusable LLM workflows

### ğŸ§  Key Concepts Explained:

- **LangChain**

  - A framework to build structured, modular GenAI applications
  - Simplifies prompt management, chaining, and LLM orchestration

- **PromptTemplate**

  - Allows dynamic prompt creation using variables
  - Helps maintain consistency and reusability in prompts

- **Batch Calls**

  - Send multiple prompts in one call
  - Improves performance and reduces overhead

- **Text Chunking**
  - Large text is split into smaller overlapping chunks
  - Prevents context length issues in LLMs

### ğŸ› ï¸ What We Built:

- Created a **ChatOpenAI** model using LangChain
- Built reusable prompts using **PromptTemplate**
- Executed:
  - **Single LLM calls**
  - **Batch LLM calls**
- Processed long text using **RecursiveCharacterTextSplitter**
- Sent chunked text to the LLM and generated explanations per chunk

This lecture focuses on **prompt engineering + scalability**, forming the base for advanced GenAI systems.

---

## ğŸ“š Lecture 08 â€“ Retrieval Augmented Generation (RAG) with LangChain

### ğŸ”§ What You'll Learn in This Lecture:

âœ… What is **Retrieval Augmented Generation (RAG)**  
âœ… Why RAG is needed over plain LLM responses  
âœ… Loading and processing external documents  
âœ… Chunking documents for better retrieval  
âœ… Creating **Embeddings** for documents  
âœ… Storing embeddings in **Chroma Vector Database**  
âœ… Performing **Similarity Search** using retrievers  
âœ… Combining retrieved context with LLM responses

### ğŸ§  Key Concepts Explained:

- **RAG (Retrieval Augmented Generation)**

  - Enhances LLMs with external knowledge
  - Prevents hallucinations
  - Answers are grounded in real documents

- **Retriever**

  - Fetches the most relevant document chunks
  - Uses vector similarity search

- **Context-Aware Prompting**
  - LLM is forced to answer using only retrieved context
  - If data is missing, model responds with `"I don't know"`

### ğŸ› ï¸ What We Built:

- Loaded a text document from local storage
- Split the document into overlapping chunks
- Generated embeddings using OpenAI Embeddings
- Stored vectors in **ChromaDB**
- Retrieved top-K relevant chunks for a query
- Passed retrieved context into a **RAG Prompt Template**
- Generated accurate, grounded answers using an LLM

### ğŸ” Example Queries:

- _"What is RAG?"_
- _"What is LangChain used for?"_
- _"Who invented Java?"_ (Correctly returns **"I don't know"**)

This lecture demonstrates a **production-grade GenAI pattern**, widely used in:

- AI chatbots
- Knowledge assistants
- Document Q&A systems

---
